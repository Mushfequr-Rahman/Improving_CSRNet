{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "from config import Config\n",
    "from model import CSRNet\n",
    "from dataset import create_train_dataloader,create_test_dataloader\n",
    "from utils import denormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jwdjj/opt/anaconda3/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "\r",
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 96, 128])\n",
      "After backend torch.Size([1, 64, 96, 128])\n",
      "After output layer:  torch.Size([1, 1, 96, 128])\n",
      "Final out torch.Size([1, 1, 768, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 1/300 [00:22<1:49:54, 22.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 50, 74])\n",
      "After backend torch.Size([1, 64, 50, 74])\n",
      "After output layer:  torch.Size([1, 1, 50, 74])\n",
      "Final out torch.Size([1, 1, 400, 592])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 2/300 [00:28<1:26:21, 17.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 80, 128])\n",
      "After backend torch.Size([1, 64, 80, 128])\n",
      "After output layer:  torch.Size([1, 1, 80, 128])\n",
      "Final out torch.Size([1, 1, 640, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 3/300 [00:52<1:35:17, 19.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 54, 128])\n",
      "After backend torch.Size([1, 64, 54, 128])\n",
      "After output layer:  torch.Size([1, 1, 54, 128])\n",
      "Final out torch.Size([1, 1, 432, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 4/300 [01:05<1:26:09, 17.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a grayscale image.\n",
      "Before backend torch.Size([1, 512, 92, 128])\n",
      "After backend torch.Size([1, 64, 92, 128])\n",
      "After output layer:  torch.Size([1, 1, 92, 128])\n",
      "Final out torch.Size([1, 1, 736, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 5/300 [01:28<1:33:42, 19.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a grayscale image.\n",
      "Before backend torch.Size([1, 512, 84, 128])\n",
      "After backend torch.Size([1, 64, 84, 128])\n",
      "After output layer:  torch.Size([1, 1, 84, 128])\n",
      "Final out torch.Size([1, 1, 672, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 6/300 [01:51<1:39:26, 20.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 42, 62])\n",
      "After backend torch.Size([1, 64, 42, 62])\n",
      "After output layer:  torch.Size([1, 1, 42, 62])\n",
      "Final out torch.Size([1, 1, 336, 496])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 7/300 [01:56<1:16:17, 15.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 80, 100])\n",
      "After backend torch.Size([1, 64, 80, 100])\n",
      "After output layer:  torch.Size([1, 1, 80, 100])\n",
      "Final out torch.Size([1, 1, 640, 800])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 8/300 [02:10<1:14:34, 15.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 84, 128])\n",
      "After backend torch.Size([1, 64, 84, 128])\n",
      "After output layer:  torch.Size([1, 1, 84, 128])\n",
      "Final out torch.Size([1, 1, 672, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 9/300 [02:31<1:22:22, 16.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 50, 80])\n",
      "After backend torch.Size([1, 64, 50, 80])\n",
      "After output layer:  torch.Size([1, 1, 50, 80])\n",
      "Final out torch.Size([1, 1, 400, 640])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 10/300 [02:38<1:08:05, 14.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 84, 128])\n",
      "After backend torch.Size([1, 64, 84, 128])\n",
      "After output layer:  torch.Size([1, 1, 84, 128])\n",
      "Final out torch.Size([1, 1, 672, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 11/300 [02:58<1:16:06, 15.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 48, 62])\n",
      "After backend torch.Size([1, 64, 48, 62])\n",
      "After output layer:  torch.Size([1, 1, 48, 62])\n",
      "Final out torch.Size([1, 1, 384, 496])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 12/300 [03:04<1:00:49, 12.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 84, 128])\n",
      "After backend torch.Size([1, 64, 84, 128])\n",
      "After output layer:  torch.Size([1, 1, 84, 128])\n",
      "Final out torch.Size([1, 1, 672, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 13/300 [03:24<1:12:18, 15.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 82, 124])\n",
      "After backend torch.Size([1, 64, 82, 124])\n",
      "After output layer:  torch.Size([1, 1, 82, 124])\n",
      "Final out torch.Size([1, 1, 656, 992])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 14/300 [03:43<1:16:38, 16.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 72, 128])\n",
      "After backend torch.Size([1, 64, 72, 128])\n",
      "After output layer:  torch.Size([1, 1, 72, 128])\n",
      "Final out torch.Size([1, 1, 576, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 15/300 [04:00<1:18:25, 16.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 42, 126])\n",
      "After backend torch.Size([1, 64, 42, 126])\n",
      "After output layer:  torch.Size([1, 1, 42, 126])\n",
      "Final out torch.Size([1, 1, 336, 1008])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 16/300 [04:10<1:08:25, 14.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 96, 128])\n",
      "After backend torch.Size([1, 64, 96, 128])\n",
      "After output layer:  torch.Size([1, 1, 96, 128])\n",
      "Final out torch.Size([1, 1, 768, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 17/300 [04:35<1:23:23, 17.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 84, 128])\n",
      "After backend torch.Size([1, 64, 84, 128])\n",
      "After output layer:  torch.Size([1, 1, 84, 128])\n",
      "Final out torch.Size([1, 1, 672, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 18/300 [04:59<1:31:34, 19.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 48, 72])\n",
      "After backend torch.Size([1, 64, 48, 72])\n",
      "After output layer:  torch.Size([1, 1, 48, 72])\n",
      "Final out torch.Size([1, 1, 384, 576])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▋         | 19/300 [05:05<1:12:51, 15.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 74, 112])\n",
      "After backend torch.Size([1, 64, 74, 112])\n",
      "After output layer:  torch.Size([1, 1, 74, 112])\n",
      "Final out torch.Size([1, 1, 592, 896])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 20/300 [05:23<1:15:43, 16.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 96, 128])\n",
      "After backend torch.Size([1, 64, 96, 128])\n",
      "After output layer:  torch.Size([1, 1, 96, 128])\n",
      "Final out torch.Size([1, 1, 768, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 21/300 [05:47<1:26:43, 18.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 84, 128])\n",
      "After backend torch.Size([1, 64, 84, 128])\n",
      "After output layer:  torch.Size([1, 1, 84, 128])\n",
      "Final out torch.Size([1, 1, 672, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 22/300 [06:09<1:30:08, 19.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 74, 128])\n",
      "After backend torch.Size([1, 64, 74, 128])\n",
      "After output layer:  torch.Size([1, 1, 74, 128])\n",
      "Final out torch.Size([1, 1, 592, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 23/300 [06:27<1:27:48, 19.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 84, 128])\n",
      "After backend torch.Size([1, 64, 84, 128])\n",
      "After output layer:  torch.Size([1, 1, 84, 128])\n",
      "Final out torch.Size([1, 1, 672, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 24/300 [06:47<1:29:46, 19.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 74, 100])\n",
      "After backend torch.Size([1, 64, 74, 100])\n",
      "After output layer:  torch.Size([1, 1, 74, 100])\n",
      "Final out torch.Size([1, 1, 592, 800])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 25/300 [07:01<1:21:22, 17.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 84, 128])\n",
      "After backend torch.Size([1, 64, 84, 128])\n",
      "After output layer:  torch.Size([1, 1, 84, 128])\n",
      "Final out torch.Size([1, 1, 672, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▊         | 26/300 [07:23<1:27:16, 19.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 40, 128])\n",
      "After backend torch.Size([1, 64, 40, 128])\n",
      "After output layer:  torch.Size([1, 1, 40, 128])\n",
      "Final out torch.Size([1, 1, 320, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 27/300 [07:33<1:13:41, 16.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 84, 128])\n",
      "After backend torch.Size([1, 64, 84, 128])\n",
      "After output layer:  torch.Size([1, 1, 84, 128])\n",
      "Final out torch.Size([1, 1, 672, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 28/300 [07:54<1:20:00, 17.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 84, 128])\n",
      "After backend torch.Size([1, 64, 84, 128])\n",
      "After output layer:  torch.Size([1, 1, 84, 128])\n",
      "Final out torch.Size([1, 1, 672, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 29/300 [08:13<1:22:35, 18.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 64, 128])\n",
      "After backend torch.Size([1, 64, 64, 128])\n",
      "After output layer:  torch.Size([1, 1, 64, 128])\n",
      "Final out torch.Size([1, 1, 512, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 30/300 [08:30<1:19:34, 17.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 82, 128])\n",
      "After backend torch.Size([1, 64, 82, 128])\n",
      "After output layer:  torch.Size([1, 1, 82, 128])\n",
      "Final out torch.Size([1, 1, 656, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 31/300 [08:51<1:24:33, 18.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 80, 128])\n",
      "After backend torch.Size([1, 64, 80, 128])\n",
      "After output layer:  torch.Size([1, 1, 80, 128])\n",
      "Final out torch.Size([1, 1, 640, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 32/300 [09:13<1:28:12, 19.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 52, 78])\n",
      "After backend torch.Size([1, 64, 52, 78])\n",
      "After output layer:  torch.Size([1, 1, 52, 78])\n",
      "Final out torch.Size([1, 1, 416, 624])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 33/300 [09:21<1:11:54, 16.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 58, 44])\n",
      "After backend torch.Size([1, 64, 58, 44])\n",
      "After output layer:  torch.Size([1, 1, 58, 44])\n",
      "Final out torch.Size([1, 1, 464, 352])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█▏        | 34/300 [09:25<55:54, 12.61s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a grayscale image.\n",
      "Before backend torch.Size([1, 512, 80, 128])\n",
      "After backend torch.Size([1, 64, 80, 128])\n",
      "After output layer:  torch.Size([1, 1, 80, 128])\n",
      "Final out torch.Size([1, 1, 640, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 35/300 [09:47<1:07:53, 15.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 84, 128])\n",
      "After backend torch.Size([1, 64, 84, 128])\n",
      "After output layer:  torch.Size([1, 1, 84, 128])\n",
      "Final out torch.Size([1, 1, 672, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 36/300 [10:09<1:16:40, 17.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 84, 128])\n",
      "After backend torch.Size([1, 64, 84, 128])\n",
      "After output layer:  torch.Size([1, 1, 84, 128])\n",
      "Final out torch.Size([1, 1, 672, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 37/300 [10:31<1:22:15, 18.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 64, 128])\n",
      "After backend torch.Size([1, 64, 64, 128])\n",
      "After output layer:  torch.Size([1, 1, 64, 128])\n",
      "Final out torch.Size([1, 1, 512, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 38/300 [10:48<1:19:41, 18.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 32, 50])\n",
      "After backend torch.Size([1, 64, 32, 50])\n",
      "After output layer:  torch.Size([1, 1, 32, 50])\n",
      "Final out torch.Size([1, 1, 256, 400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 39/300 [10:52<59:53, 13.77s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 84, 128])\n",
      "After backend torch.Size([1, 64, 84, 128])\n",
      "After output layer:  torch.Size([1, 1, 84, 128])\n",
      "Final out torch.Size([1, 1, 672, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 40/300 [11:14<1:10:48, 16.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 82, 128])\n",
      "After backend torch.Size([1, 64, 82, 128])\n",
      "After output layer:  torch.Size([1, 1, 82, 128])\n",
      "Final out torch.Size([1, 1, 656, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▎        | 41/300 [11:34<1:15:20, 17.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 84, 128])\n",
      "After backend torch.Size([1, 64, 84, 128])\n",
      "After output layer:  torch.Size([1, 1, 84, 128])\n",
      "Final out torch.Size([1, 1, 672, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 42/300 [11:54<1:19:03, 18.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 94, 128])\n",
      "After backend torch.Size([1, 64, 94, 128])\n",
      "After output layer:  torch.Size([1, 1, 94, 128])\n",
      "Final out torch.Size([1, 1, 752, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 43/300 [12:19<1:26:52, 20.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 58, 46])\n",
      "After backend torch.Size([1, 64, 58, 46])\n",
      "After output layer:  torch.Size([1, 1, 58, 46])\n",
      "Final out torch.Size([1, 1, 464, 368])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 44/300 [12:25<1:07:22, 15.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 96, 128])\n",
      "After backend torch.Size([1, 64, 96, 128])\n",
      "After output layer:  torch.Size([1, 1, 96, 128])\n",
      "Final out torch.Size([1, 1, 768, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 45/300 [12:52<1:21:31, 19.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 102, 128])\n",
      "After backend torch.Size([1, 64, 102, 128])\n",
      "After output layer:  torch.Size([1, 1, 102, 128])\n",
      "Final out torch.Size([1, 1, 816, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 46/300 [13:19<1:31:16, 21.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 56, 36])\n",
      "After backend torch.Size([1, 64, 56, 36])\n",
      "After output layer:  torch.Size([1, 1, 56, 36])\n",
      "Final out torch.Size([1, 1, 448, 288])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 47/300 [13:22<1:08:24, 16.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 52, 76])\n",
      "After backend torch.Size([1, 64, 52, 76])\n",
      "After output layer:  torch.Size([1, 1, 52, 76])\n",
      "Final out torch.Size([1, 1, 416, 608])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 48/300 [13:30<57:16, 13.64s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 84, 128])\n",
      "After backend torch.Size([1, 64, 84, 128])\n",
      "After output layer:  torch.Size([1, 1, 84, 128])\n",
      "Final out torch.Size([1, 1, 672, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▋        | 49/300 [13:52<1:07:54, 16.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 76, 126])\n",
      "After backend torch.Size([1, 64, 76, 126])\n",
      "After output layer:  torch.Size([1, 1, 76, 126])\n",
      "Final out torch.Size([1, 1, 608, 1008])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 50/300 [14:12<1:11:29, 17.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 86, 128])\n",
      "After backend torch.Size([1, 64, 86, 128])\n",
      "After output layer:  torch.Size([1, 1, 86, 128])\n",
      "Final out torch.Size([1, 1, 688, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 51/300 [14:35<1:18:52, 19.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 96, 128])\n",
      "After backend torch.Size([1, 64, 96, 128])\n",
      "After output layer:  torch.Size([1, 1, 96, 128])\n",
      "Final out torch.Size([1, 1, 768, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 52/300 [14:57<1:22:24, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 46, 62])\n",
      "After backend torch.Size([1, 64, 46, 62])\n",
      "After output layer:  torch.Size([1, 1, 46, 62])\n",
      "Final out torch.Size([1, 1, 368, 496])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 53/300 [15:02<1:03:26, 15.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 96, 128])\n",
      "After backend torch.Size([1, 64, 96, 128])\n",
      "After output layer:  torch.Size([1, 1, 96, 128])\n",
      "Final out torch.Size([1, 1, 768, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 54/300 [15:23<1:09:54, 17.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 62, 94])\n",
      "After backend torch.Size([1, 64, 62, 94])\n",
      "After output layer:  torch.Size([1, 1, 62, 94])\n",
      "Final out torch.Size([1, 1, 496, 752])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 55/300 [15:32<1:00:07, 14.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 48, 78])\n",
      "After backend torch.Size([1, 64, 48, 78])\n",
      "After output layer:  torch.Size([1, 1, 48, 78])\n",
      "Final out torch.Size([1, 1, 384, 624])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▊        | 56/300 [15:38<49:15, 12.11s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 32, 62])\n",
      "After backend torch.Size([1, 64, 32, 62])\n",
      "After output layer:  torch.Size([1, 1, 32, 62])\n",
      "Final out torch.Size([1, 1, 256, 496])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 57/300 [15:42<38:25,  9.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 82, 102])\n",
      "After backend torch.Size([1, 64, 82, 102])\n",
      "After output layer:  torch.Size([1, 1, 82, 102])\n",
      "Final out torch.Size([1, 1, 656, 816])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 58/300 [15:56<44:00, 10.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 68, 116])\n",
      "After backend torch.Size([1, 64, 68, 116])\n",
      "After output layer:  torch.Size([1, 1, 68, 116])\n",
      "Final out torch.Size([1, 1, 544, 928])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 59/300 [16:09<46:40, 11.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 22, 58])\n",
      "After backend torch.Size([1, 64, 22, 58])\n",
      "After output layer:  torch.Size([1, 1, 22, 58])\n",
      "Final out torch.Size([1, 1, 176, 464])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 60/300 [16:11<35:00,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 98, 128])\n",
      "After backend torch.Size([1, 64, 98, 128])\n",
      "After output layer:  torch.Size([1, 1, 98, 128])\n",
      "Final out torch.Size([1, 1, 784, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 61/300 [16:32<49:43, 12.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 84, 128])\n",
      "After backend torch.Size([1, 64, 84, 128])\n",
      "After output layer:  torch.Size([1, 1, 84, 128])\n",
      "Final out torch.Size([1, 1, 672, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 62/300 [16:52<58:36, 14.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backend torch.Size([1, 512, 50, 76])\n",
      "After backend torch.Size([1, 64, 50, 76])\n",
      "After output layer:  torch.Size([1, 1, 50, 76])\n",
      "Final out torch.Size([1, 1, 400, 608])\n"
     ]
    }
   ],
   "source": [
    "cfg = Config()                                                          # configuration\n",
    "continue_training = False\n",
    "\n",
    "model = CSRNet().to(cfg.device) \n",
    "\n",
    "if continue_training:\n",
    "    model.load_state_dict(torch.load('checkpoints/shaghai_tech_a_best.pth') )                                        # GPU\n",
    "    # torch.load('checkpoints/shaghai_tech_a_best.pth', map_location=lambda storage, loc: storage)  # CPU\n",
    "                                                                        # model\n",
    "criterion = nn.MSELoss(size_average=False)                              # objective\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=cfg.lr)              # optimizer\n",
    "train_dataloader = create_train_dataloader(cfg.dataset_root, use_flip=True, batch_size=cfg.batch_size)\n",
    "test_dataloader  = create_test_dataloader(cfg.dataset_root)             # dataloader\n",
    "\n",
    "min_mae = sys.maxsize\n",
    "min_mae_epoch = -1\n",
    "for epoch in range(1, cfg.epochs):                                      # start training\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for i, data in enumerate(tqdm(train_dataloader)):\n",
    "        image = data['image'].to(cfg.device)\n",
    "        gt_densitymap = data['densitymap'].to(cfg.device)\n",
    "        et_densitymap = model(image)                        # forward propagation\n",
    "        loss = criterion(et_densitymap,gt_densitymap)       # calculate loss\n",
    "        epoch_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()                                     # back propagation\n",
    "        optimizer.step()                                    # update network parameters\n",
    "    cfg.writer.add_scalar('Train_Loss', epoch_loss/len(train_dataloader), epoch)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        epoch_mae = 0.0\n",
    "        for i, data in enumerate(tqdm(test_dataloader)):\n",
    "            image = data['image'].to(cfg.device)\n",
    "            gt_densitymap = data['densitymap'].to(cfg.device)\n",
    "            et_densitymap = model(image).detach()           # forward propagation\n",
    "            mae = abs(et_densitymap.data.sum()-gt_densitymap.data.sum())\n",
    "            epoch_mae += mae.item()\n",
    "        epoch_mae /= len(test_dataloader)\n",
    "        if epoch_mae < min_mae:\n",
    "            min_mae, min_mae_epoch = epoch_mae, epoch\n",
    "            torch.save(model.state_dict(), os.path.join(cfg.checkpoints,str(epoch)+\".pth\"))     # save checkpoints\n",
    "        print('Epoch ', epoch, ' MAE: ', epoch_mae, ' Min MAE: ', min_mae, ' Min Epoch: ', min_mae_epoch)   # print information\n",
    "        cfg.writer.add_scalar('Val_MAE', epoch_mae, epoch)\n",
    "        cfg.writer.add_image(str(epoch)+'/Image', denormalize(image[0].cpu()))\n",
    "        cfg.writer.add_image(str(epoch)+'/Estimate density count:'+ str('%.2f'%(et_densitymap[0].cpu().sum())), et_densitymap[0]/torch.max(et_densitymap[0]))\n",
    "        cfg.writer.add_image(str(epoch)+'/Ground Truth count:'+ str('%.2f'%(gt_densitymap[0].cpu().sum())), gt_densitymap[0]/torch.max(gt_densitymap[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
